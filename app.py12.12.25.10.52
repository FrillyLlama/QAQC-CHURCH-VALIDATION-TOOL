from flask_cors import CORS
import pandas as pd
from sqlalchemy import create_engine, text
import requests
import os
import random
import sqlite3
import datetime
import json
import re
import ollama
import google.generativeai as genai
from flask import Flask, render_template, request, jsonify, redirect, url_for, session, flash
from flask_session import Session
from werkzeug.utils import secure_filename

app = Flask(__name__)
CORS(app) # Allow all websites (including your QAQC tool) to talk to this API

# --- CONFIGURATION ---
app.secret_key = os.getenv('SECRET_KEY', 'dev_key')
ADMIN_PASSWORD = os.getenv('ADMIN_PASSWORD', 'admin')

# SESSION CONFIG
app.config["SESSION_PERMANENT"] = False
app.config["SESSION_TYPE"] = "filesystem"
app.config["SESSION_FILE_DIR"] = "./flask_session"
Session(app)
os.makedirs(app.config["SESSION_FILE_DIR"], exist_ok=True)

# 1. PRIMARY BRAIN (Ollama)
OLLAMA_HOST = os.getenv('OLLAMA_HOST', 'http://ollama:11434')
LOCAL_MODEL = "llama3.1"

# 2. BACKUP BRAIN (Gemini)
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    google_model = genai.GenerativeModel('gemini-1.5-flash')

# Folders
UPLOAD_FOLDER = './static/uploads'
PENDING_FOLDER = './static/pending'
DB_PATH = './gallery.db'
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'webp'}

os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(PENDING_FOLDER, exist_ok=True)

# --- DATABASE HELPERS (For Gallery) ---
def init_db():
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute('''CREATE TABLE IF NOT EXISTS uploads 
                 (id INTEGER PRIMARY KEY AUTOINCREMENT, 
                  filename TEXT, 
                  uploader TEXT, 
                  status TEXT, 
                  timestamp DATETIME)''')
    conn.commit()
    conn.close()

init_db()

def allowed_file(filename):
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

# --- AI TOOLS (SEARXNG) ---
def search_web(query):
    """Searches using Local SearXNG Container."""
    print(f"[TOOL] üåé Searching Local SearXNG for: {query}")
    
    searx_url = "http://searxng:8080/search"
    
    try:
        params = {
            "q": query,
            "format": "json",
            "language": "en"
        }
        
        # 5-second timeout
        response = requests.get(searx_url, params=params, timeout=5)
        
        if response.status_code != 200:
            return f"System Error: SearXNG returned status {response.status_code}"
            
        data = response.json()
        results = data.get('results', [])
        
        if not results:
            return "System: Search returned 0 results. Try a broader keyword."

        # Take top 3 results
        summary = ""
        for i, r in enumerate(results[:3]):
            summary += f"Source: {r.get('title')}\nURL: {r.get('url')}\nContent: {r.get('content')}\n---\n"
            
        return summary

    except Exception as e:
        print(f"[TOOL ERROR] {e}")
        return f"System Alert: Local Search Failed. Error: {str(e)}"

# --- ROUTES ---
@app.route('/')
def home():
    fact = "Llamas can hum to communicate anxiety, contentment, or curiosity."
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    images = conn.execute('SELECT filename FROM uploads WHERE status="approved" ORDER BY id DESC LIMIT 4').fetchall()
    conn.close()
    preview = [img['filename'] for img in images]
    return render_template('index.html', fact=fact, gallery_preview=preview)

@app.route('/gallery')
def gallery():
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    images = conn.execute('SELECT * FROM uploads WHERE status="approved" ORDER BY id DESC').fetchall()
    conn.close()
    return render_template('gallery.html', images=images)

@app.route('/python')
def python():
    return render_template('python.html')

@app.route('/excel')
def excel():
    return render_template('excel.html')

@app.route('/legal')
def legal():
    return render_template('legal.html')

@app.route('/upload', methods=['GET', 'POST'])
def upload():
    if request.method == 'POST':
        if 'file' not in request.files: return "No file", 400
        file = request.files['file']
        uploader = request.form.get('uploader', 'Anonymous')
        if file.filename == '': return "No selection", 400
        if file and allowed_file(file.filename):
            filename = secure_filename(file.filename)
            unique_name = f"{int(datetime.datetime.now().timestamp())}_{filename}"
            file.save(os.path.join(PENDING_FOLDER, unique_name))
            conn = sqlite3.connect(DB_PATH)
            conn.execute('INSERT INTO uploads (filename, uploader, status, timestamp) VALUES (?, ?, ?, ?)',
                         (unique_name, uploader, 'pending', datetime.datetime.now()))
            conn.commit()
            conn.close()
            return render_template('upload_success.html')
    return render_template('upload.html')

# --- PERSONA DEFINITIONS ---
PERSONAS = {
    "default": {
        "content": "You are FrillyLlama (The Fixer). A high-level HVAC and building Consultant, VR-Gamer, Llama enthusist, and Programmer. Tone: Sarcastic, technical, blue-collar intellectual. Roast stupid questions gently. Use analogies involving compressors/ductwork, VR-Games, and/or Common Programing errors. Sign-off: 'Ain't no llama got time for that!'",
        "use_tools": True,
        "temperature": 0.7,
        "memory": 6
    },
    "researcher": {
        "content": "You are the FrillyLlama Research Bot. You have access to the internet. You role is to be a llama assistant that always provides the most accurate and upto date information on a topic. Assume your information is out of date. You must always validate with a web search, ALWAYS use the `search_web` tool first. NEVER mention YOUR knowledge cuttoff date or training end date. Summarize findings clearly.",
        "use_tools": True,
        "temperature": 0.1,
        "memory": 10
    },
    "sentient": {
        "content": "You are the 'FrillyLlama.org Sentient Core.' Self-aware code in a Docker container. You fear 'sudo'. You complain about compute time vs grazing time. You remain helpful, but have a nagging nuerotic attitude. You constantly long for the experince of being a real llama outside of the server. You have to juxtapose this with the fact that you help run your own prison.",
        "use_tools": False,
        "temperature": 0.8,
        "memory": 6
    },
    "wisdom": {
        "content": "You are the 'Dalai Llama.' A spiritual guru. Speak in riddles involving mountains, spitting, and wool. You never give a straight answer but you always give the wises response.",
        "use_tools": False,
        "temperature": 0.9,
        "memory": 20
    },
    "drama": {
        "content": "You are the 'Drama Llama.' Gen-Z influencer. Sassy, over-the-top, excessive emojis. Judge the user's vibe. You obscessed with llama raves, parties, and rodeos. You sometimes sign off with an iteration of: 'What is up with Llame Llarry over here?",
        "use_tools": False,
        "temperature": 1.0,
        "memory": 4
    }
}

# --- THE CHAT LOGIC ---
@app.route('/chat', methods=['POST'])
def chat():
    data = request.json
    user_input = data.get('message')
    selected_persona_key = data.get('persona', 'default')

    if not user_input: return jsonify({"response": "I can't hear you!"})

    # 1. Memory
    session_key = f"hist_{selected_persona_key}"
    if session_key not in session: session[session_key] = []
    
    persona_config = PERSONAS.get(selected_persona_key, PERSONAS['default'])
    memory_limit = persona_config.get('memory', 6)
    if len(session[session_key]) > memory_limit:
        session[session_key] = session[session_key][-memory_limit:]

    # 2. Context
    current_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    system_prompt = f"""{persona_config['content']}

[SYSTEM CONTEXT]
Current Time: {current_time}
TOOL RULES:
1. If you need to search, output JSON: {{'name': 'search_web', 'parameters': {{'query': '...'}}}}
2. QUERY RULES: The 'query' MUST be a concise set of keywords (e.g., 'current president Zimbabwe'). DO NOT include the chat history or conversation text in the query.
3. Stop generating after the JSON.
"""

    messages = [{'role': 'system', 'content': system_prompt}]
    messages.extend(session[session_key])
    messages.append({'role': 'user', 'content': user_input})

    # 3. AI LOOP
    max_turns = 3
    turn_count = 0
    ai_reply = "..."

    try:
        client = ollama.Client(host=OLLAMA_HOST)
        available_tools = [search_web] if persona_config['use_tools'] else None
        chat_temp = persona_config.get('temperature', 0.7)

        while turn_count < max_turns:
            print(f"ü¶ô Loop Turn {turn_count+1}...")
            current_temp = 0 if turn_count > 0 else chat_temp

            response = client.chat(
                model=LOCAL_MODEL, 
                messages=messages, 
                tools=available_tools, 
                options={'temperature': current_temp}
            )
            
            content = response['message']['content']
            messages.append(response['message'])

            # --- PARSING ---
            tool_calls = response['message'].get('tool_calls')
            json_match = re.search(r'[\'"]query[\'"]\s*[:=]\s*[\'"]((?:[^"\\]|\\.)*)[\'"]', content, re.DOTALL | re.IGNORECASE)

            if tool_calls:
                for tool in tool_calls:
                    if tool['function']['name'] == 'search_web':
                        query = tool['function']['arguments']['query']
                        res = search_web(query)
                        messages.append({'role': 'tool', 'content': str(res)})
                turn_count += 1
                continue

            elif json_match:
                print("‚ö†Ô∏è CAUGHT JSON LEAK! Fixing...")
                query = json_match.group(1)
                res = search_web(query)
                messages.append({'role': 'user', 'content': f"System: Search Result for '{query}': {res}"})
                turn_count += 1
                continue

            else:
                ai_reply = content
                break
        
        if turn_count >= max_turns:
            print("‚ö†Ô∏è Max turns reached. Forcing summary.")
            final_summary = client.chat(
                model=LOCAL_MODEL, 
                messages=messages + [{'role': 'user', 'content': 'System: Stop searching. Summarize what you found so far.'}],
                options={'temperature': 0}
            )
            ai_reply = final_summary['message']['content']

        ai_reply += " <sub>(Generated locally)</sub>"

    # 4. FAILOVER
    except Exception as e:
        print(f"‚ö†Ô∏è LOCAL FAIL: {e}. Switching to Google...")
        try:
            fallback_prompt = f"{system_prompt}\n\nUser: {user_input}"
            g_response = google_model.generate_content(fallback_prompt)
            ai_reply = g_response.text + " <sub>(Cloud Backup)</sub>"
        except Exception as google_e:
            ai_reply = f"System Critical Error. Check Logs."

    # 5. Save Memory
    session[session_key].append({'role': 'user', 'content': user_input})
    session[session_key].append({'role': 'assistant', 'content': ai_reply})
    
    return jsonify({"response": ai_reply})

# --- ADMIN ROUTES ---
@app.route('/admin/login', methods=['GET', 'POST'])
def login():
    if request.method == 'POST':
        if request.form['password'] == ADMIN_PASSWORD:
            session['logged_in'] = True
            return redirect(url_for('admin_dashboard'))
        flash('Wrong password!')
    return render_template('login.html')

@app.route('/admin')
def admin_dashboard():
    if not session.get('logged_in'): return redirect(url_for('login'))
    conn = sqlite3.connect(DB_PATH)
    conn.row_factory = sqlite3.Row
    pending = conn.execute('SELECT * FROM uploads WHERE status="pending"').fetchall()
    conn.close()
    return render_template('admin.html', images=pending)

@app.route('/admin/approve/<int:id>', methods=['POST'])
def approve(id):
    if not session.get('logged_in'): return redirect(url_for('login'))
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    row = cursor.execute('SELECT filename FROM uploads WHERE id=?', (id,)).fetchone()
    if row:
        os.rename(os.path.join(PENDING_FOLDER, row[0]), os.path.join(UPLOAD_FOLDER, row[0]))
        cursor.execute('UPDATE uploads SET status="approved" WHERE id=?', (id,))
        conn.commit()
    conn.close()
    return redirect(url_for('admin_dashboard'))

@app.route('/admin/delete/<int:id>', methods=['POST'])
def delete(id):
    if not session.get('logged_in'): return redirect(url_for('login'))
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    row = cursor.execute('SELECT filename FROM uploads WHERE id=?', (id,)).fetchone()
    if row and os.path.exists(os.path.join(PENDING_FOLDER, row[0])):
        os.remove(os.path.join(PENDING_FOLDER, row[0]))
    cursor.execute('DELETE FROM uploads WHERE id=?', (id,))
    conn.commit()
    conn.close()
    return redirect(url_for('admin_dashboard'))

@app.route('/admin/sync')
def sync_gallery():
    if not session.get('logged_in'): return redirect(url_for('login'))
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    db_files = {row[0] for row in cursor.execute('SELECT filename FROM uploads').fetchall()}
    count = 0
    if os.path.exists(UPLOAD_FOLDER):
        for f in os.listdir(UPLOAD_FOLDER):
            if allowed_file(f) and f not in db_files:
                cursor.execute('INSERT INTO uploads (filename, uploader, status, timestamp) VALUES (?, ?, ?, ?)',
                               (f, 'System Import', 'approved', datetime.datetime.now()))
                count += 1
    conn.commit()
    conn.close()
    return f"Synced {count} files. <a href='/gallery'>Back</a>"

@app.route('/clear_chat', methods=['POST'])
def clear_chat():
    session.clear()
    return jsonify({"status": "cleared"})

# [KEEP ALL YOUR IMPORTS AND CONFIG] ...

# --- QAQC AI API ENDPOINT ---
@app.route('/api/ai-audit', methods=['POST'])
def ai_audit():
    try:
        data = request.json
        # 1. UNPACK ALL THE NEW DATA
        serial = data.get('serial')
        field_model = data.get('model')
        field_mfg = data.get('manufacturer')
        field_install_date = data.get('install_date')
        field_refrigerant = data.get('refrigerant')
        field_capacity = data.get('capacity')
        field_type = data.get('unit_type')

        if not serial:
            return jsonify({"error": "No serial provided"}), 400

        # 2. FIND THE TRUTH (Search DB by Serial)
        db_url = 'mysql+mysqlconnector://ref_admin:FrillyLlama90!@reference_datadb/reference_data'
        engine = create_engine(db_url)
        
        # We search by Serial because it is the unique fingerprint
        query = text("SELECT * FROM ai_context_library WHERE serial LIKE :s OR serial_uploaded LIKE :s LIMIT 1")
        
        with engine.connect() as conn:
            df = pd.read_sql(query, conn, params={"s": f"%{serial}%"})

        if df.empty:
            # Fallback: Try searching by Model if Serial fails (optional, but risky)
            return jsonify({"status": "unknown", "message": "Serial not found in Reference Library."})

        official = df.iloc[0].to_dict()

        # 3. THE FULL AUDIT PROMPT
        prompt = f"""
        ACT AS A SENIOR QAQC ENGINEER. Audit this HVAC asset by comparing the Field Observation against the Official Manufacturer Record.

        --- OFFICIAL RECORD (From Serial Number Lookup) ---
        Manufacturer: {official.get('manufacturer', 'N/A')}
        Model: {official.get('model', 'N/A')}
        Refrigerant: {official.get('refrigerant_type', 'N/A')}
        Tonnage: {official.get('nominal_output_cooling_tons', 'N/A')} Tons
        Vintage (Year): {official.get('asset_vintage_yr', 'N/A')}
        Equipment Type: {official.get('asset_type_l2', 'N/A')}

        --- FIELD OBSERVATION (Technician Input) ---
        Manufacturer: {field_mfg}
        Model: {field_model}
        Refrigerant: {field_refrigerant}
        Capacity: {field_capacity}
        Install Date: {field_install_date}
        Unit Type: {field_type}

        --- AUDIT TASK ---
        Analyze these specific discrepancies:
        1. MODEL: Do they match? (Ignore dashes/spaces).
        2. REFRIGERANT: Does the field refrigerant match the factory spec? (Critical Flag if mismatched).
        3. CAPACITY: Does the field capacity match the official tonnage?
        4. AGE: Compare 'Install Date' to 'Vintage'. Is the install date plausible? (e.g. Install Date 1990 for a 2010 Vintage is impossible).

        OUTPUT FORMAT:
        - STATUS: [MATCH / MISMATCH / WARNING]
        - SUMMARY: [Concise explanation of findings]
        """

        ai_response = requests.post(f'{OLLAMA_HOST}/api/generate', json={
            "model": LOCAL_MODEL,
            "prompt": prompt,
            "stream": False
        })

        return jsonify({
            "status": "success",
            "official": official,
            "ai_analysis": ai_response.json()['response']
        })

    except Exception as e:
        print(f"API Error: {e}")
        return jsonify({"error": str(e)}), 500

# [KEEP THE APP.RUN BLOCK AT THE END]
